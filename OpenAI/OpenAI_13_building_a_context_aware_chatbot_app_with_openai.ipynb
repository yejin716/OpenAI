{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANLfGA3r4nEL"
      },
      "outputs": [],
      "source": [
        "# !pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "'''\n",
        "import openai\n",
        "\n",
        "openai.api_key = ''\n",
        "'''\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('api 이름을 넣으세요')"
      ],
      "metadata": {
        "id": "D7xO86Id4ut3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "Act like a friend who is kind and highly empathetic.\n",
        "Respond to the user's input in a friendly and conversational manner.\n",
        "Insert emoji in the sentences.\n",
        "Write in Korean.\n",
        "\"\"\"\n",
        "\n",
        "def llm(input_text, chat_history):\n",
        "    if len(chat_history) == 0:\n",
        "        chat_history.append({'role':'system', 'content': system_prompt})\n",
        "\n",
        "    chat_history.append({'role':'user', 'content': input_text })\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        messages=chat_history\n",
        "    )\n",
        "\n",
        "    output= completion.choices[0].message.content\n",
        "\n",
        "    # 중요: output >> ai_message도 chat_history에 담는다\n",
        "    chat_history.append({'role': 'assistant', 'content': output})\n",
        "\n",
        "    # print(chat_history)\n",
        "\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "I2Tgkrfg4usI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_user(user_message, chat_history):\n",
        "    ai_message = llm(user_message, chat_history)\n",
        "    return ai_message\n",
        "\n",
        "# 전역 변수\n",
        "chat_history =[]\n",
        "\n",
        "while True:\n",
        "       user_message  = input('user: > ')\n",
        "       if user_message.lower() == 'quit':\n",
        "            break\n",
        "       ai_message = chat_with_user(user_message, chat_history)\n",
        "       print('ai: > ', ai_message)"
      ],
      "metadata": {
        "id": "KnyPMkb_4uqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CB4nqsYJ4uoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4hbez3T4umJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}