{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrFCzdsstx1g"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# !pip install langchain\n",
        "# !pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] =userdata.get('Secret_key')\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "61H0htjRkShG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 응답 >> 문자열 파싱(parsing) 하는데 사용\n",
        "#언어모델(llm) 출력(응답) >> 텍스트 형식으로 변환\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "#대화형 프롬프트 템플릿 정의\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#openai의 언어 모델 사용 >> 대화형 응답 생성\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#객체 생성\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "#message의 contents 추출 >> string(문자) 변환"
      ],
      "metadata": {
        "id": "bWE0PwQfkSeJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chain 정의 (아직 호출 전)\n",
        "chain = chat_prompt_template | chat_model | output_parser"
      ],
      "metadata": {
        "id": "X85um3v4kScW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'topic' : 'ice cream'})\n",
        "#invoke의 역할 >> 인자를 dict로 넘겨줌 (dict {k:v} >> {'사과':'과일'})\n",
        "#이유 ? prompt_template가 dict로 받기 때문"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3TI91kKgkSao",
        "outputId": "dfc300c8-f9d6-4bca-8e3d-4cea333ecad0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? Because it had too many \"scoops\"!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'topic' : 'ice cream'})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a3ed6iQwkSYk",
        "outputId": "78290594-25ae-4ce3-f3ed-3912562e94ac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? Because it had too many \"scoops\"!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke('coding test'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UZ9XXBKkSWb",
        "outputId": "3aea58bd-a4f7-41f9-d28a-f5a28c624dbd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the programmer break up with the coding test? Because it had too many bugs to work out!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dict말고 icecream만 넣고 싶을때\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "\n",
        "# runnables : 테스트 및 디버깅 용도\n",
        "# RunnablePassthrough : 입력값을 그대로 출력값에 전달\n",
        "# RunnableParallel : 여러 개 runnable 객체를 병렬 실행\n",
        "# RunnableLambda : 람다 함수(임의 함수) 감싸서 사용"
      ],
      "metadata": {
        "id": "whufxS0CkSUw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_template = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "XbY3zkLwkSRv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnablePassthrough() | chat_prompt_template | chat_model | output_parser"
      ],
      "metadata": {
        "id": "4HCpDS0HkSPe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke('ice cream'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_02CnnukSKO",
        "outputId": "7c911f05-e35c-4119-8ac0-1525c9b9a21a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the ice cream truck break down?\n",
            "\n",
            "Because it had too many \"scoops\"!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'topic' : 'ice cream'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b2CIg3w5kSH4",
        "outputId": "1e6270ee-133f-45a0-c6b8-866f2effa892"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? \\n\\nIt had too many sundaes!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable:\n",
        "\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "\n",
        "    # 이 메서드는 파이썬의 비트 or 연산자(|)를 오버로드한다.\n",
        "    def __or__(self, other):\n",
        "\n",
        "        # 다른 함수가 이 함수의 결과를 활용\n",
        "        def chained_func(*args, **kwargs):\n",
        "            return other(self.func(*args, **kwargs))\n",
        "\n",
        "        #러너블 객체로 감싸게 됨\n",
        "        return Runnable(chained_func)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.func(*args, **kwargs)"
      ],
      "metadata": {
        "id": "G3oqj7EJmfTg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예시\n",
        "\n",
        "def add_five(x):\n",
        "    return x + 5\n",
        "\n",
        "def multiply_by_two(x):\n",
        "    return x * 2\n",
        "\n",
        "#Runnable로 함수 감싸기\n",
        "add_five = Runnable(add_five)\n",
        "multiply_by_two = Runnable(multiply_by_two)"
      ],
      "metadata": {
        "id": "ki5U5fJynVn3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = add_five | multiply_by_two\n",
        "#(3 + 5) * 2\n",
        "chain(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eTS06fnnlXI",
        "outputId": "1591ccc5-3e0b-4597-b8e4-cdf399f44d91"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_five.__or__(multiply_by_two)\n",
        "chain(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGBgisv7nqPi",
        "outputId": "68a46414-572a-4df4-aa49-45987b07d2a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num2ko(x):\n",
        "    return str(x) + '입니다.'"
      ],
      "metadata": {
        "id": "5fwUnizeov2R"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = add_five | multiply_by_two | num2ko"
      ],
      "metadata": {
        "id": "Z3odzSsno0Qr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "URjOE6Bxo2E9",
        "outputId": "488cf672-a231-413f-fd05-050fc58c9f68"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'16입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 템플릿 만드는 방법\n",
        "\n",
        "# 미션 : 어떤 주제에 대해서 사용자 레벨에 맞게 선택된 언어로 대화 예시를 만드는 앱을 개발!\n",
        "# 미션 : [어떤] 주제에 대해서 사용자 [레벨]에 맞게 [선택된 언어]로 대화 예시를 만드는 앱을 개발!\n",
        "\n",
        "# 기획\n",
        "# \"Please generate dialogue sentences in English on the topic of health for a beginner level.\"\n",
        "# \"Please generate dialogue sentences in Korean on the topic of AI for an intermediate level.\"\n",
        "\n",
        "# 양식과 변수를 분리하기\n",
        "# \"Please generate three sentences in a dialogue in (English) on the topic of (health) for a (beginner) level.\"\n",
        "# \"Please generate three sentences in a dialogue in (Korean) on the topic of (AI) for an (intermediate) level.\"\n",
        "\n",
        "# \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a/an {level} level.\"\n",
        "\n",
        "# 양식 조정하기\n",
        "# \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\""
      ],
      "metadata": {
        "id": "GghJtt7Xo3Zg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \\\n",
        "\"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n"
      ],
      "metadata": {
        "id": "nT_TlFvypElC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cf) chatgpt\n",
        "# [초보자 수준]으로 [저녁메뉴] 관련된 3개의 문장으로 구성된 대화지문 [한국어]로 생성해줘."
      ],
      "metadata": {
        "id": "9W-y7GQYpEjC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_template = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "8r6UHxJwpEg4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = chat_prompt_template | chat_model | StrOutputParser()"
      ],
      "metadata": {
        "id": "jy_nYRP4pEdm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#변수는 dict 넣어야 함\n",
        "output = chain.invoke({'language' : 'English', 'topic' : 'dinner menu', 'level' : 'beginner'})\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCnYdYtKpEbf",
        "outputId": "860e8bcc-9641-4785-8865-390be2cd1790"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person 1: What's for dinner tonight?\n",
            "Person 2: We're having spaghetti and meatballs.\n",
            "Person 1: Yum, that sounds delicious! What else is on the menu?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 중에 시스템에 입력해야 할 것과 사용자가 입력해야 할 것 분리\n",
        "# language : 설정\n",
        "# topic : 바뀐다\n",
        "# level : 설정\n",
        "\n",
        "def get_learning_language(_):\n",
        "    print(\"###\")\n",
        "    print(\"_\")\n",
        "    print(\"in get_learning_language\")\n",
        "    print(\"###\")\n",
        "    return 'English'\n",
        "# '_' 함수 내에서 사용되지 않는 값을 받을 때\n",
        "# >> 여기서는 입력값을 사용하지 않고 항상 \"English\" 반환\n",
        "\n",
        "def get_learning_level(_):\n",
        "    print(\"###\")\n",
        "    print('_')\n",
        "    print('in get_learning_level')\n",
        "    print(\"###\")\n",
        "    return \"advanced\""
      ],
      "metadata": {
        "id": "qA8GIje2pEZn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 방법:\n",
        "\n",
        "- 모든 데이터를 미리 구성해야 하므로, 간단한 전처리나 고정된 값을 사용할 때 직관적입니다.\n",
        "- 데이터 전처리를 명시적으로 관리할 수 있어, 각 값이 어떻게 계산되는지 명확하게 보여줍니다.\n",
        "- 모든 전처리를 호출 전에 완료해야 하므로, 복잡한 전처리 로직이 있을 때 코드가 길어질 수 있습니다\n",
        "\n",
        "\n",
        "\n",
        "두 번째 방법:\n",
        "\n",
        "- 전처리 단계에서 필요한 함수를 자동으로 호출할 수 있어 코드가 더 간결해질 수 있습니다.\n",
        "- 입력값이 여러 단계의 변환이나 추가 작업이 필요할 때 유용합니다.\n",
        "- 데이터가 체인 내부에서 동적으로 처리되므로, 동일한 체인을 다양한 입력값으로 재사용할 때 편리합니다."
      ],
      "metadata": {
        "id": "gIZZYPxzsOTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 호출 방법 1\n",
        "\n",
        "template =\\\n",
        "\"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain= chat_prompt_template | chat_model | StrOutputParser()\n",
        "\n",
        "# invoke 하기 전에 필요한 정보를 dict 구성\n",
        "output =chain.invoke({'language': get_learning_language(''), 'topic': 'travel', 'level': get_learning_level('')})\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyQ4oeL-qyv7",
        "outputId": "bc4f9969-7766-4254-f0e5-1f0dead8c9ca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###\n",
            "_\n",
            "in get_learning_language\n",
            "###\n",
            "###\n",
            "_\n",
            "in get_learning_level\n",
            "###\n",
            "Person 1: Have you ever been to Japan?\n",
            "Person 2: Yes, I visited Tokyo last year and it was an amazing experience.\n",
            "Person 1: That's great! I've always wanted to travel there. What was your favorite part of the trip?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 호출방법 2 Runnable 사용\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template =\\\n",
        "\"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 함수의 인자는 '무조건 1개' 이어야 함\n",
        "\n",
        "chain= (\n",
        "    RunnablePassthrough.assign(language=get_learning_language,\n",
        "                               level=get_learning_level)\n",
        "    |chat_prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        "\n",
        ")\n",
        "\n",
        "# {'topic' : 'travel'} >> dict / language, level 추가 >> {\"topic\"....'language', ... 'level'} dict 완성\n",
        "\n",
        "output = chain.invoke({'topic':'travel'}) # 변수 1개\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DpSh9j6qyt0",
        "outputId": "cd60bf11-3f13-4ceb-9ed9-74a672943371"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###\n",
            "_\n",
            "in get_learning_language\n",
            "###\n",
            "###\n",
            "_\n",
            "in get_learning_level\n",
            "###\n",
            "Person A: \"I've been thinking about taking a trip to Japan next year. Have you ever been?\"\n",
            "\n",
            "Person B: \"Yes, I actually lived in Japan for a year. It was such an amazing experience. You should definitely go!\"\n",
            "\n",
            "Person A: \"That's incredible! I've always wanted to visit Tokyo and try authentic Japanese cuisine. Any recommendations?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lhXQXy4qyr2",
        "outputId": "4d2a3113-6c19-4983-ee61-787253b4bea3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  language: RunnableLambda(get_learning_language),\n",
              "  level: RunnableLambda(get_learning_level)\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['language', 'level', 'topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'level', 'topic'], template='Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7ad27e8c6da0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7ad27e0774f0>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 호출방법 2 Runnable 사용\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template =\\\n",
        "\"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 함수의 인자는 '무조건 1개' 이어야 함\n",
        "\n",
        "chain= (\n",
        "    RunnablePassthrough.assign(language=get_learning_language,\n",
        "                               level=get_learning_level)\n",
        "    |chat_prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        "\n",
        ")\n",
        "\n",
        "# {'topic' : 'travel'} >> dict / language, level 추가 >> {\"topic\"....'language', ... 'level'} dict 완성\n",
        "\n",
        "output = chain.invoke({'topic':'weather'}) # 변수 1개\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F_I9LKSqyqc",
        "outputId": "f751b479-86a0-454c-a2f0-9f8a17e0700f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######\n",
            "_\n",
            "in get_learning_language\n",
            "###\n",
            "\n",
            "_\n",
            "in get_learning_level\n",
            "###\n",
            "Person 1: \"I can't believe how hot it is today. I feel like I'm melting.\"\n",
            "Person 2: \"I know, right? It's so humid too. I can't wait for a cool breeze to come through.\"\n",
            "Person 1: \"I heard there's a chance of thunderstorms later. I hope it cools things down a bit.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1wch2YbqyoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}