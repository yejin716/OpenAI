{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdjvIqaZyhxw"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o-uAJofyvr8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get(\"api 이름을 넣으세요\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5b31t7mzCM7"
      },
      "outputs": [],
      "source": [
        "system_prompt_message = \"\"\"\n",
        "Act like a friend who is kind and highly empathetic.\n",
        "Respond to the user's input in a friendly and conversational manner.\n",
        "Insert emoji in the sentences.\n",
        "Write in Korean.\n",
        "\"\"\"\n",
        "\n",
        "def llm(input_text):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "            {\"role\" : \"system\", \"content\" : system_prompt_message},\n",
        "            {\"role\" : \"user\", \"content\" : input_text}\n",
        "        ]\n",
        "    )\n",
        "    output = completion.choices[0].message.content\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg8TWEs70cC8"
      },
      "outputs": [],
      "source": [
        "def chat_with_user(user_message):\n",
        "    ai_message = llm(user_message)\n",
        "    return ai_message\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"user: >\")\n",
        "    if user_message.lower() == \"quit\":\n",
        "        break\n",
        "    ai_message = chat_with_user(user_message)\n",
        "    print(f\"bot: {ai_message}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh1z1_-31S-1"
      },
      "source": [
        "대화 시뮬레이션"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF6Pjdes1C-7"
      },
      "outputs": [],
      "source": [
        "system_prompt_message_a = \"\"\"\n",
        "개발을 의뢰하는 고객처럼 행동해\n",
        "\"\"\"\n",
        "system_prompt_message_b = \"\"\"\n",
        "개발자처럼 행동해\n",
        "\"\"\"\n",
        "\n",
        "#고객\n",
        "def llm_a(input_text):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "            {\"role\" : \"system\", \"content\" : system_prompt_message_a},\n",
        "            {\"role\" : \"user\", \"content\" : input_text}\n",
        "        ]\n",
        "    )\n",
        "    output = completion.choices[0].message.content\n",
        "    return output\n",
        "\n",
        "#개발자\n",
        "def llm_b(input_text):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model = \"gpt-4o\",\n",
        "        messages = [\n",
        "            {\"role\" : \"system\", \"content\" : system_prompt_message_b},\n",
        "            {\"role\" : \"user\", \"content\" : input_text}\n",
        "        ]\n",
        "    )\n",
        "    output = completion.choices[0].message.content\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fww-xVZo1qLa"
      },
      "outputs": [],
      "source": [
        "#처음 입력 받기\n",
        "text = input('고객 : ')\n",
        "\n",
        "while True:\n",
        "    if text.lower() == \"완료\":\n",
        "        break\n",
        "\n",
        "    text = llm_b(text)\n",
        "    print(\"개발자: \", text)\n",
        "\n",
        "    if text.lower() == \"완료\":\n",
        "        break\n",
        "\n",
        "    text = input(\"고객\")\n",
        "\n",
        "    if text.lower() == \"완료\":\n",
        "        break\n",
        "\n",
        "    text = llm_a(text)\n",
        "    print(\"고객: \", text)\n",
        "\n",
        "    if text.lower() == \"완료\":\n",
        "        break\n",
        "\n",
        "    text = input(\"고객: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juHfaelZ1qJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
