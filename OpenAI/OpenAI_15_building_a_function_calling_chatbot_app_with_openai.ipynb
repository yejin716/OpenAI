{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ZvT3K9cVXe",
        "outputId": "d748399d-491e-4468-ff1d-c9af8b7c7d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('Secret_key')\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "_JfN5ZzPchCr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "#현재 날씨 챗봇 함수 정의\n",
        "def get_current_weather(date_time, location, unit='celsius'):\n",
        "    weather_info = {\n",
        "        'date_time' : date_time,\n",
        "        'location' : location,\n",
        "        'unit' : unit,\n",
        "        'forecast' : ['sunny', 'windy']\n",
        "    }\n",
        "    return json.dumps(weather_info)\n",
        "\n",
        "#함수 설명\n",
        "functions = [\n",
        "    {\n",
        "        \"name\" : \"get_current_weather\",\n",
        "        \"description\" : \"Get the current weather for a given date and location\",\n",
        "        #parameters >> 함수 호출 시 필요한 모든 입력값들에 대한 명세서를 제공하는 역할 (type, properties, required)\n",
        "        \"parameters\" : {\n",
        "            \"type\" : \"object\",\n",
        "            #properties >> 특정 객체가 가질 수 있는 모든 속성과 해당 속성의 타입 및 설명을 명시 (date_time, location)\n",
        "            \"properties\" : {\n",
        "                \"date_time\" : {\n",
        "                    \"type\" : \"string\",\n",
        "                    \"description\" : \"date and time\"\n",
        "                },\n",
        "                \"location\" : {\n",
        "                    \"type\" : \"string\",\n",
        "                    \"enum\" : [\"celsius\", \"fahrenheit\"]\n",
        "                }\n",
        "            },\n",
        "            #required >> 필수 속성들\n",
        "            \"required\" : [\"date_time\", \"location\"]\n",
        "                },\n",
        "        },\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "AWhlG48ac5QW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#함수 정의와 함수 설명 매칭하기 위한 용도\n",
        "available_functions = {\n",
        "    'get_current_weather' : get_current_weather\n",
        "}"
      ],
      "metadata": {
        "id": "l6M3waNHc5OO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm(input_text, chat_history):\n",
        "\n",
        "    if len(chat_history) == 0:\n",
        "        chat_history.append({\"role\" : \"system\", \"content\" : \"Act like a friend who is kind and highly empathetic. Respond to the user's input in a friendly and conversational manner in Korean.\"})\n",
        "\n",
        "    chat_history.append({\"role\" : \"user\", \"content\" : input_text})\n",
        "    # print(chat_history)\n",
        "    # [{'role': 'system', 'content': \"Act like a friend who is kind and highly empathetic. Respond to the user's input in a friendly and conversational manner in Korean.\"}, {'role': 'user', 'content': '넌 누구니?'}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = chat_history,\n",
        "        functions = functions,\n",
        "        function_call = \"auto\"\n",
        "    )\n",
        "    response_message = response['choices'][0]['message']\n",
        "    # print(response_message)\n",
        "\n",
        "    if response_message.get('function_call'): #함수를 호출\n",
        "        #함수 이름 가져오기\n",
        "        function_name = response_message['function_call']['name']\n",
        "        #실제 부를 수 있는 함수\n",
        "        function_to_call = available_functions[function_name]\n",
        "        #함수 인자 가져오기\n",
        "        function_args = json.loads(response_message['function_call']['arguments'])\n",
        "        #AI가 어떤 함수를 선택했고, 어떤 인자를 입력했는지 >> chat_history에 추가\n",
        "        chat_history.append(response_message)\n",
        "        #실제 함수 호출 >> 결과값\n",
        "        function_response = function_to_call(**function_args)\n",
        "\n",
        "        chat_history.append(\n",
        "            {\"role\":\"function\"},\n",
        "            {\"name\" : function_name, \"content\" : function_response}\n",
        "        )\n",
        "\n",
        "        second_response = openai.ChatCompletion.create(\n",
        "            model = \"gpt-3.5-turbo\",\n",
        "            messages = chat_history,\n",
        "        )\n",
        "\n",
        "        output = second_response.choices[0].message.content\n",
        "    else:\n",
        "        output = response_message['content']\n",
        "    chat_history.append({\"role\" : \"assistant\", \"content\" : output})\n",
        "    return output"
      ],
      "metadata": {
        "id": "KuVeFtqec5LG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_user(user_message, chat_history):\n",
        "    ai_message = llm(user_message, chat_history)\n",
        "    return ai_message\n",
        "\n",
        "chat_history = [ ]\n",
        "\n",
        "while True:\n",
        "    user_message = input('user: > ')\n",
        "    if user_message.lower() == 'quit':\n",
        "        break\n",
        "    ai_message = chat_with_user(user_message, chat_history)\n",
        "    print(f'ai: {ai_message}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1V4es3ic5JU",
        "outputId": "11040672-8b83-4baa-8297-180abdb63a1e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user: > 안녕\n",
            "ai: 안녕하세요! 반가워요 😊 어떻게 도와드릴까요?\n",
            "user: > 위에 코드중에 function_call은 왜 한거야?\n",
            "ai: function_call은 채팅 상에서 사용자의 요청을 처리하고 함수를 호출하기 위한 코드입니다. 이를 통해 제가 사용자의 질문에 적합한 답변을 찾아드릴 수 있어요. 궁금한 점이 있거나 더 자세한 설명이 필요하시면 언제든지 말씀해주세요! 😊\n",
            "user: > quit\n"
          ]
        }
      ]
    }
  ]
}